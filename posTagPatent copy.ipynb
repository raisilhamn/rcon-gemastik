{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trailing data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# read data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m'\u001b[39;49m\u001b[39mpatent.json\u001b[39;49m\u001b[39m'\u001b[39;49m, orient\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrecords\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m data \u001b[39m=\u001b[39m data[[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mabstract_localized.text\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m      5\u001b[0m data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\json\\_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[0;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 784\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\json\\_json.py:975\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    976\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m    977\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mconvert_dtypes(\n\u001b[0;32m    978\u001b[0m         infer_objects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype_backend\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype_backend\n\u001b[0;32m    979\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\json\\_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    999\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1001\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[0;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\json\\_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 1134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n\u001b[0;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\json\\_json.py:1347\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m parse_table_schema(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\n\u001b[0;32m   1345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1347\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Trailing data"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_json('patent.json', orient='records')\n",
    "data = data[[\"title\", \"abstract_localized.text\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_localized.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire detection system based on artificial inte...</td>\n",
       "      <td>The present disclosure relates to a fire detec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embedding artificial intelligence for balancin...</td>\n",
       "      <td>Responsive to a CPU load of a specific access ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optimization techniques for artificial intelli...</td>\n",
       "      <td>Methods, apparatuses and computer readable med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Method to create a secure distributed data val...</td>\n",
       "      <td>Methods and apparatus for validating paper for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virtual game assistant based on artificial int...</td>\n",
       "      <td>Virtual game dealers based on artificial intel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Fire detection system based on artificial inte...   \n",
       "2  Embedding artificial intelligence for balancin...   \n",
       "4  Optimization techniques for artificial intelli...   \n",
       "6  Method to create a secure distributed data val...   \n",
       "8  Virtual game assistant based on artificial int...   \n",
       "\n",
       "                             abstract_localized.text  \n",
       "0  The present disclosure relates to a fire detec...  \n",
       "2  Responsive to a CPU load of a specific access ...  \n",
       "4  Methods, apparatuses and computer readable med...  \n",
       "6  Methods and apparatus for validating paper for...  \n",
       "8  Virtual game dealers based on artificial intel...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing value\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fire detection system based on artificial inte...\n",
       "2    Embedding artificial intelligence for balancin...\n",
       "4    Optimization techniques for artificial intelli...\n",
       "6    Method to create a secure distributed data val...\n",
       "8    Virtual game assistant based on artificial int...\n",
       "Name: clean_msg, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "data['clean_msg'] = data['title'].apply(lambda x:remove_punctuation(str(x)))\n",
    "data['clean_msg'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fire detection system based on artificial inte...\n",
       "2    embedding artificial intelligence for balancin...\n",
       "4    optimization techniques for artificial intelli...\n",
       "6    method to create a secure distributed data val...\n",
       "8    virtual game assistant based on artificial int...\n",
       "Name: msg_lower, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowering text\n",
    "\n",
    "data['msg_lower']= data['clean_msg'].apply(lambda x: x.lower())\n",
    "data['msg_lower'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0      [fire, detection, system, based, on, artificia...\n",
       "2      [embedding, artificial, intelligence, for, bal...\n",
       "4      [optimization, techniques, for, artificial, in...\n",
       "6      [method, to, create, a, secure, distributed, d...\n",
       "8      [virtual, game, assistant, based, on, artifici...\n",
       "                             ...                        \n",
       "490    [systems, and, methods, for, artificial, intel...\n",
       "492    [wearable, computing, apparatus, for, augmente...\n",
       "494    [system, and, method, of, providing, and, reco...\n",
       "496    [method, and, server, for, optimizing, hyperpa...\n",
       "498    [fallback, artificial, intelligence, system, f...\n",
       "Name: msg_tokenized, Length: 266, dtype: object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization\n",
    "\n",
    "data['msg_tokenized'] = data['msg_lower'].apply(nltk.word_tokenize)\n",
    "data['msg_tokenized'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0      [fire, detection, system, based, artificial, i...\n",
       "2      [embedding, artificial, intelligence, balancin...\n",
       "4      [optimization, techniques, artificial, intelli...\n",
       "6      [method, create, secure, distributed, data, va...\n",
       "8      [virtual, game, assistant, based, artificial, ...\n",
       "                             ...                        \n",
       "490    [systems, methods, artificial, intelligencegui...\n",
       "492    [wearable, computing, apparatus, augmented, re...\n",
       "494    [system, method, providing, recording, persona...\n",
       "496    [method, server, optimizing, hyperparameter, t...\n",
       "498    [fallback, artificial, intelligence, system, r...\n",
       "Name: no_stopwords, Length: 266, dtype: object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "data['no_stopwords']= data['msg_tokenized'].apply(lambda x:remove_stopwords(x))\n",
    "data['no_stopwords'].head"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(fire, NN), (detection, NN), (system, NN), (b...\n",
       "2    [(embedding, VBG), (artificial, JJ), (intellig...\n",
       "4    [(optimization, NN), (techniques, NNS), (artif...\n",
       "6    [(method, NN), (create, NN), (secure, NN), (di...\n",
       "8    [(virtual, JJ), (game, NN), (assistant, NN), (...\n",
       "Name: tagged, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tagged'] = data['no_stopwords'].apply(nltk.pos_tag)\n",
    "data['tagged'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_word(word, tag):\n",
    "    if tag.startswith('V'):\n",
    "        return lemmatizer.lemmatize(word, 'v')  # Verb\n",
    "    elif tag.startswith('N'):\n",
    "        return lemmatizer.lemmatize(word, 'n')  # Noun\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "2    [(balance, access), (process, load), (enable, ...\n",
       "4                                                   []\n",
       "6          [(distribute, data), (distribute, storage)]\n",
       "8                                                   []\n",
       "Name: verb_noun_pairs, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos chunk\n",
    "\n",
    "def filter_verb_noun_pairs(tagged_sentence):\n",
    "    verb_noun_pairs = []\n",
    "    for i in range(len(tagged_sentence) - 1):\n",
    "        word, tag = tagged_sentence[i]\n",
    "        next_word, next_tag = tagged_sentence[i + 1]\n",
    "        if tag.startswith('VB') and next_tag.startswith('NN'):\n",
    "            verb = lemmatize_word(word, tag)\n",
    "            noun = lemmatize_word(next_word, next_tag)\n",
    "            verb_noun_pairs.append((verb, noun))\n",
    "    return verb_noun_pairs\n",
    "\n",
    "data['verb_noun_pairs'] = data['tagged'].apply(filter_verb_noun_pairs)\n",
    "data['verb_noun_pairs'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>verb_noun_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire detection system based on artificial inte...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embedding artificial intelligence for balancin...</td>\n",
       "      <td>[(balance, access), (process, load), (enable, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optimization techniques for artificial intelli...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Method to create a secure distributed data val...</td>\n",
       "      <td>[(distribute, data), (distribute, storage)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virtual game assistant based on artificial int...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Systems and methods for artificial intelligenc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Wearable computing apparatus for augmented rea...</td>\n",
       "      <td>[(compute, apparatus), (augment, reality), (re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>System and method of providing and recording p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Method and server for optimizing hyperparamete...</td>\n",
       "      <td>[(optimize, hyperparameter)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Fallback artificial intelligence system for re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Fire detection system based on artificial inte...   \n",
       "2    Embedding artificial intelligence for balancin...   \n",
       "4    Optimization techniques for artificial intelli...   \n",
       "6    Method to create a secure distributed data val...   \n",
       "8    Virtual game assistant based on artificial int...   \n",
       "..                                                 ...   \n",
       "490  Systems and methods for artificial intelligenc...   \n",
       "492  Wearable computing apparatus for augmented rea...   \n",
       "494  System and method of providing and recording p...   \n",
       "496  Method and server for optimizing hyperparamete...   \n",
       "498  Fallback artificial intelligence system for re...   \n",
       "\n",
       "                                       verb_noun_pairs  \n",
       "0                                                   []  \n",
       "2    [(balance, access), (process, load), (enable, ...  \n",
       "4                                                   []  \n",
       "6          [(distribute, data), (distribute, storage)]  \n",
       "8                                                   []  \n",
       "..                                                 ...  \n",
       "490                                                 []  \n",
       "492  [(compute, apparatus), (augment, reality), (re...  \n",
       "494                                                 []  \n",
       "496                       [(optimize, hyperparameter)]  \n",
       "498                                                 []  \n",
       "\n",
       "[266 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hasile\n",
    "\n",
    "patent_task = data[[\"title\", \"verb_noun_pairs\"]]\n",
    "patent_task.to_excel('patent_task.xlsx', index=False)\n",
    "patent_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
